---
layout: post
title: Rob AI Project
categories: intro ai robozzle rob data game
excerpt_separator: <!--more-->
---
Almost ten years ago my university roommates discovered a very interesting and
challenging programming game: [RoboZZle](http://www.robozzle.com/beta/).
We spent weeks writing little programs for a robot, that would navigate a
labyrinth to collect rewards. Now as a small step towards self-programming AI
we are launching a project to beat RoboZZle programming game with machine learning.

# Introduction

## About the game

There are thousands of community-made puzzles. Puzzles are 16x12 fields
with cells colored red, green, blue, or black (impassable). There's also a robot,
and a set of one or more rewards to collect.

![Example Field]({{ site.baseurl }}/images/Evil-Green.png)

<!--more-->

The task is to write a program for the robot to collect all rewards.

A program consists of 1-5 functions of fixed length (specified by a puzzle).
Commands are limited to movement, turns, calling other functions
(with a typical stack semantics), and sometimes cell repainting.
An example instruction set:

![Example instruction set]({{ site.baseurl }}/images/instruction-set.png)

Colored instructions are conditional - they only execute if the robot
is on a cell with corresponding color.

You can see an example solution in action:

![Sample run]({{ site.baseurl }}/images/sample-play.gif)

# Getting there

## Data collection

Having the right training data is the most important part of any machine
learning process. While we could have tried to make computer sort of teach
itself, it is usually much easier to give it examples to learn from.

So we turned to the community.

The data we want here is a step-by-step list of operations an actual human does.
E.g.

1. start with an empty program
1. replace command 1 with "Go Forward"
1. replace command 2 with "Call F0"
1. run the program and watch the robot fail miserably
1. replace command 2 with "Turn Left on Green"
1. rerun
1. etc

![Solving Two Functions]({{ site.baseurl }}/images/solving-two-functions.gif)

If we collect enough of these sequences, we can use a supervised learning
algorithm to predict the next action a human would make in a given state to
solve the puzzle.

Right now we collect this data (with user consent) when folks play our
[Android game port](https://play.google.com/store/apps/details?id=com.team242.robozzle&hl=en)
or its [Windows Store brother](https://www.microsoft.com/en-us/store/p/rob-programming-game/9nblggh5fkh6#)
(PC, Xbox, Mobile, and Hololens).

## Predicting the next move

With the abovementioned data, guessing the next human move is just a
classification task. Input data is a picture of the game field,
current program, and also a number of steps the robot has made since start
(if it is currently running). Output is what to do next: edit the puzzle
(also, how to?) or start or stop the robot.

It would be inefficient to feed the training algorithm with actual
screenshots from the game, as they would have relatively high resolution.
Instead, in our current approach we encode game state and current program
as a small (51x31) grayscale image, where colors are encoded with brightness.

For example, this is how a solving session for
[The Chambers](http://robozzle.com/js/play.aspx?puzzle=38) puzzle
looks like to our initial model:

![Telemetry from The Chambers puzzle]({{ site.baseurl }}/images/38-the-chambers-session.gif)

The man figure is the actual field, grey area below him is the user program,
and the line, that grows from the left side encodes the editing history.

You might notice how "man" rotates and the program shifts. Its our attempt
to aid neural network to match current position and rotation with the next
command(s) robot is about to execute. Which we will talk about in later posts.

# Going forward

We have just started building a
[convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network)
model to fit this data.

Why convolution? Because important puzzle elements are typical for 2D images:
edges and corners, color-coded turns, repeatable 2D patterns. Usually,
[LSTMs](https://en.wikipedia.org/wiki/LSTM) are used for generating sequences
(like a program editing action sequence), however I believe CNNs just might work
better if augmented with some historical information.

In the next post I will share more details about how we preprocess and generate
training data from user telemetry.

Meanwhile, you can join our project by playing the game on
[Android](https://play.google.com/store/apps/details?id=com.team242.robozzle&hl=en)
or [Windows](https://www.microsoft.com/en-us/store/p/rob-programming-game/9nblggh5fkh6#).

Stay tuned for more!

[Sign up](https://goo.gl/forms/Yp8NkYisTwrq60Hu1) for updates over email or to leave a comment.
You can also subscribe to RSS with the link in the footer.